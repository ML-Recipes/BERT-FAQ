{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "07.Generating_Reranked_Results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIhLk6uIODF",
        "outputId": "b8d8f5d9-95bf-484f-c7ae-d16121a6194c"
      },
      "source": [
        "# install required libraries\n",
        "!pip3 install sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4d/9fb1028b0b4645c77401417151d06122d745c7a874fda6a4d5e6bb7bebc6/sentence-transformers-1.0.3.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.2)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.3-cp37-none-any.whl size=114277 sha256=b5524e0351c87beb2af5e0e636d17165b3b19ec9e113c892a6e880a24b6c9d70\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/0d/fa/4e28cf045da4781344e7972befb2fdf306051b225bfc290187\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=992aec4c4c229ea83ddb4681e7a30432bd4c8d71e7b40b511999cb508ab3c677\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-1.0.3 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHrXaJsSLhrJ",
        "outputId": "50f448aa-b359-4843-d887-3301d8626d15"
      },
      "source": [
        "!pip3 install elasticsearch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/93/461a042becf2a35a666fb7dbb2fa31f0f766dfd1b01e7d971f4ad51f0d69/elasticsearch-7.12.0-py2.py3-none-any.whl (334kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 26.2MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 25.9MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 23.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 23.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 16.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 18.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 16.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 163kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 215kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 266kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 317kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 327kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 18.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2020.12.5)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6PkXGeh5s3"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-v9U9E5h5gb",
        "outputId": "b0d7f488-b33f-42e4-9e0f-2458f1b111a7"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMP1Wg7Bh5RT",
        "outputId": "8024faf1-cecb-4c52-b2e0-ed272cbd9127"
      },
      "source": [
        "%cd /content/drive/MyDrive/BERT-FAQ"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BERT-FAQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ESSxl0XiXAD",
        "outputId": "83b1cf9a-41b1-4c65-8664-5adf8097ae94"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t     metric.py\t       reranker.py\n",
            "evaluation.py\t\t     notebook\t       searcher.py\n",
            "faq_bert_finetuning.py\t     output\t       shared\n",
            "faq_bert.py\t\t     parser\t       training_data_generator.py\n",
            "faq_bert_ranker.py\t     __pycache__       webserver.py\n",
            "hard_negatives_generator.py  README.md\n",
            "indexer.py\t\t     requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6mIC_NKTRR"
      },
      "source": [
        "# import required dependencies\n",
        "from evaluation import get_relevance_label_df\n",
        "from shared.utils import load_from_json\n",
        "from shared.utils import dump_to_json\n",
        "from shared.utils import make_dirs\n",
        "from reranker import ReRanker"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O3F8NYk19Go"
      },
      "source": [
        "output_path=\"data/FAQIR/rank_results\"\n",
        "\n",
        "# load user_query ES results from json files\n",
        "es_output_path = output_path + \"/unsupervised\"\n",
        "es_query_by_question = load_from_json(es_output_path + '/es_query_by_question.json')\n",
        "es_query_by_answer = load_from_json(es_output_path + '/es_query_by_answer.json')\n",
        "es_query_by_question_answer = load_from_json(es_output_path + '/es_query_by_question_answer.json')\n",
        "es_query_by_question_answer_concat = load_from_json(es_output_path + '/es_query_by_question_answer_concat.json')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA4nPfi1885"
      },
      "source": [
        "# load test_queries, relevance_label_df for ReRanker\n",
        "query_answer_pair_filepath = 'data/FAQIR/query_answer_pairs.json'\n",
        "relevance_label_df = get_relevance_label_df(query_answer_pair_filepath)\n",
        "test_queries = relevance_label_df[relevance_label_df['query_type'] == 'user_query'].question.unique()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhodYHua180S",
        "outputId": "b2e49956-b045-423e-8b48-394307f9e753"
      },
      "source": [
        "test_queries[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How to increase the efficiency of my car with respect to fuel expended?',\n",
              "       'Is there a special way to drive to decreasse my fuel consumption?',\n",
              "       'How to use less gas in my car?',\n",
              "       'I want to save some money on gas. What can I do to make my car use less gas?',\n",
              "       'Are there any simple tweaks one can do to a car to make it more fuel efficient?',\n",
              "       'How can I make my fuel mileage bigger?',\n",
              "       'I feel my car is using too much gas. Can I make some cheap modifications that would fix this?',\n",
              "       'What should I do to reduce the fuel required by my car while not affecting the mileage?',\n",
              "       'I need to decrease the fuel consumption of my car. What are the best strategies?',\n",
              "       'I have a sporty style of driving, can I reduce the fuel consumption by changing the driving style?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2S73_R42DCF",
        "outputId": "b7b2bc01-6116-4d41-9d2c-4a695450bdcd"
      },
      "source": [
        "# total number of test queries\n",
        "len(test_queries)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-El9_2qsn20-"
      },
      "source": [
        "**#################### Triplet Loss ######################**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcqS2Dj2liG"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jcFHSRBZSY"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ycYBipNnP9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJMgG4aZKTN5",
        "outputId": "57bcb065-56b7-4117-d636-6bc5b19a2237"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 17:32:10 - Generating BERT top-k results ...\n",
            "2021-03-23 17:32:11 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 17:32:11 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 17:32:19 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:58<00:00,  1.23it/s]\n",
            "2021-03-23 17:48:20 - Re-ranking the top-k results ...\n",
            "2021-03-23 17:48:22 - Generating BERT top-k results ...\n",
            "2021-03-23 17:48:22 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 17:48:22 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 17:48:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [17:13<00:00,  1.14it/s]\n",
            "2021-03-23 18:05:40 - Re-ranking the top-k results ...\n",
            "2021-03-23 18:05:42 - Generating BERT top-k results ...\n",
            "2021-03-23 18:05:42 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 18:05:42 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 18:05:43 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:33<00:00,  1.19it/s]\n",
            "2021-03-23 18:22:19 - Re-ranking the top-k results ...\n",
            "2021-03-23 18:22:21 - Generating BERT top-k results ...\n",
            "2021-03-23 18:22:21 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 18:22:21 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_user_query_1.1\n",
            "2021-03-23 18:22:23 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:15<00:00,  1.21it/s]\n",
            "2021-03-23 18:38:41 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5fBXXCM8oo"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YahPWqlrM4eU"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfz-PNgZM4FL"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jQn9shzcsj",
        "outputId": "74d0095d-7245-465f-a55a-b53e7d9c5144"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 18:38:44 - Generating BERT top-k results ...\n",
            "2021-03-23 18:38:44 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 18:38:44 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 18:38:55 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [18:54<00:00,  1.04it/s]\n",
            "2021-03-23 18:57:52 - Re-ranking the top-k results ...\n",
            "2021-03-23 18:57:54 - Generating BERT top-k results ...\n",
            "2021-03-23 18:57:54 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 18:57:54 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 18:57:56 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [24:09<00:00,  1.23s/it]\n",
            "2021-03-23 19:22:08 - Re-ranking the top-k results ...\n",
            "2021-03-23 19:22:11 - Generating BERT top-k results ...\n",
            "2021-03-23 19:22:11 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 19:22:11 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 19:22:12 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [22:05<00:00,  1.12s/it]\n",
            "2021-03-23 19:44:21 - Re-ranking the top-k results ...\n",
            "2021-03-23 19:44:23 - Generating BERT top-k results ...\n",
            "2021-03-23 19:44:23 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 19:44:23 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_user_query_1.1\n",
            "2021-03-23 19:44:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [21:01<00:00,  1.07s/it]\n",
            "2021-03-23 20:05:28 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-VLGZ-Np04"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGUqO4kSNcGJ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkdb3DQON4A9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9whF6pZTzfHK",
        "outputId": "e7fa379a-c98d-46f9-c4f8-1a00a4e8f8a6"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 20:05:32 - Generating BERT top-k results ...\n",
            "2021-03-23 20:05:32 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:05:32 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:05:42 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:32<00:00,  1.27it/s]\n",
            "2021-03-23 20:21:17 - Re-ranking the top-k results ...\n",
            "2021-03-23 20:21:19 - Generating BERT top-k results ...\n",
            "2021-03-23 20:21:19 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:21:19 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:21:20 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [17:03<00:00,  1.16it/s]\n",
            "2021-03-23 20:38:27 - Re-ranking the top-k results ...\n",
            "2021-03-23 20:38:29 - Generating BERT top-k results ...\n",
            "2021-03-23 20:38:29 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:38:29 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:38:30 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:28<00:00,  1.20it/s]\n",
            "2021-03-23 20:55:01 - Re-ranking the top-k results ...\n",
            "2021-03-23 20:55:04 - Generating BERT top-k results ...\n",
            "2021-03-23 20:55:04 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:55:04 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_hard_faq_1.1\n",
            "2021-03-23 20:55:05 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:11<00:00,  1.22it/s]\n",
            "2021-03-23 21:11:20 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW6WhP1POh4R"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td1x8prBOXIo"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZPxcmWOny9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWO9iOd4zjrX",
        "outputId": "a2dbfcb7-fc26-46d7-8374-7d4c1cd05c32"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 21:11:24 - Generating BERT top-k results ...\n",
            "2021-03-23 21:11:24 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:11:24 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:11:35 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:31<00:00,  1.27it/s]\n",
            "2021-03-23 21:27:08 - Re-ranking the top-k results ...\n",
            "2021-03-23 21:27:10 - Generating BERT top-k results ...\n",
            "2021-03-23 21:27:10 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:27:10 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:27:12 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [17:05<00:00,  1.15it/s]\n",
            "2021-03-23 21:44:20 - Re-ranking the top-k results ...\n",
            "2021-03-23 21:44:22 - Generating BERT top-k results ...\n",
            "2021-03-23 21:44:22 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:44:22 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 21:44:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:28<00:00,  1.20it/s]\n",
            "2021-03-23 22:00:54 - Re-ranking the top-k results ...\n",
            "2021-03-23 22:00:57 - Generating BERT top-k results ...\n",
            "2021-03-23 22:00:57 - Load pretrained SentenceTransformer: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 22:00:57 - Load SentenceTransformer from folder: output/FAQIR/models/triplet_simple_faq_1.1\n",
            "2021-03-23 22:00:58 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:11<00:00,  1.22it/s]\n",
            "2021-03-23 22:17:12 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdMinNw0tEBa"
      },
      "source": [
        "**##################### Softmax Loss #####################**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQWBMnXNuN1r"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWbql3bypSdF"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbORhXguIpu"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxveUtZbzlnb",
        "outputId": "89480bda-fcc8-4b9d-e25b-5837813a91bc"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 22:17:16 - Generating BERT top-k results ...\n",
            "2021-03-23 22:17:27 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [14:37<00:00,  1.35it/s]\n",
            "2021-03-23 22:32:07 - Re-ranking the top-k results ...\n",
            "2021-03-23 22:32:09 - Generating BERT top-k results ...\n",
            "2021-03-23 22:32:12 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:39<00:00,  1.18it/s]\n",
            "2021-03-23 22:48:54 - Re-ranking the top-k results ...\n",
            "2021-03-23 22:48:56 - Generating BERT top-k results ...\n",
            "2021-03-23 22:48:58 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:54<00:00,  1.24it/s]\n",
            "2021-03-23 23:04:55 - Re-ranking the top-k results ...\n",
            "2021-03-23 23:04:58 - Generating BERT top-k results ...\n",
            "2021-03-23 23:04:59 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:31<00:00,  1.27it/s]\n",
            "2021-03-23 23:20:34 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLHtw4zugOk"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPKGt7ktRLQ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMO_kPHtRBO"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vUWF6aUzmvS",
        "outputId": "86d3cb96-e540-4f8f-9418-8b04902b458b"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-23 23:20:37 - Generating BERT top-k results ...\n",
            "2021-03-23 23:20:49 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [14:41<00:00,  1.34it/s]\n",
            "2021-03-23 23:35:33 - Re-ranking the top-k results ...\n",
            "2021-03-23 23:35:35 - Generating BERT top-k results ...\n",
            "2021-03-23 23:35:37 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:42<00:00,  1.18it/s]\n",
            "2021-03-23 23:52:23 - Re-ranking the top-k results ...\n",
            "2021-03-23 23:52:26 - Generating BERT top-k results ...\n",
            "2021-03-23 23:52:27 - Use pytorch device: cuda\n",
            " 87%|████████▋ | 1026/1183 [13:47<02:08,  1.22it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_coGmXjKvm5u"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSr5tQKGvp1f",
        "outputId": "0ff5a913-3501-4cd0-fa09-db32a372d40a"
      },
      "source": [
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 05:39:49 - Generating BERT top-k results ...\n",
            "2021-03-24 05:39:58 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:06<00:00,  1.22it/s]\n",
            "2021-03-24 05:56:07 - Re-ranking the top-k results ...\n",
            "2021-03-24 05:56:09 - Generating BERT top-k results ...\n",
            "2021-03-24 05:56:11 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:42<00:00,  1.26it/s]\n",
            "2021-03-24 06:11:56 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDZBk_GvM1z"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtGmXzrtQda"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzg0l8rEtQZh"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q_F0a8Qzon2",
        "outputId": "e7be73e1-a2e3-4559-aad8-dd92c202258d"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 06:11:59 - Generating BERT top-k results ...\n",
            "2021-03-24 06:12:10 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [14:51<00:00,  1.33it/s]\n",
            "2021-03-24 06:27:04 - Re-ranking the top-k results ...\n",
            "2021-03-24 06:27:06 - Generating BERT top-k results ...\n",
            "2021-03-24 06:27:08 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:58<00:00,  1.16it/s]\n",
            "2021-03-24 06:44:10 - Re-ranking the top-k results ...\n",
            "2021-03-24 06:44:13 - Generating BERT top-k results ...\n",
            "2021-03-24 06:44:15 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:03<00:00,  1.23it/s]\n",
            "2021-03-24 07:00:20 - Re-ranking the top-k results ...\n",
            "2021-03-24 07:00:23 - Generating BERT top-k results ...\n",
            "2021-03-24 07:00:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:49<00:00,  1.25it/s]\n",
            "2021-03-24 07:16:16 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2EgbhAkvgUc"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tUfy5fOtP2M"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/FAQIR/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x94VfKuitPva"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzcVcYUwzqLm",
        "outputId": "79f8cc88-155b-4b47-e7ca-4dcc011c06dd"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-24 07:16:19 - Generating BERT top-k results ...\n",
            "2021-03-24 07:16:31 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:11<00:00,  1.30it/s]\n",
            "2021-03-24 07:31:45 - Re-ranking the top-k results ...\n",
            "2021-03-24 07:31:47 - Generating BERT top-k results ...\n",
            "2021-03-24 07:31:49 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [16:54<00:00,  1.17it/s]\n",
            "2021-03-24 07:48:46 - Re-ranking the top-k results ...\n",
            "2021-03-24 07:48:48 - Generating BERT top-k results ...\n",
            "2021-03-24 07:48:50 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:56<00:00,  1.24it/s]\n",
            "2021-03-24 08:04:49 - Re-ranking the top-k results ...\n",
            "2021-03-24 08:04:51 - Generating BERT top-k results ...\n",
            "2021-03-24 08:04:53 - Use pytorch device: cuda\n",
            "100%|██████████| 1183/1183 [15:35<00:00,  1.26it/s]\n",
            "2021-03-24 08:20:31 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FWIvlvG7QFB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}