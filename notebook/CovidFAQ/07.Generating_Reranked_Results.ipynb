{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWIhLk6uIODF",
    "outputId": "a046cb12-9e43-4df1-9c71-5a87fa3c2631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
      "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 33.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 50.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 48.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
      "Building wheels for collected packages: sentence-transformers, sacremoses\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp37-none-any.whl size=103068 sha256=379fa0d768d7c3a5b77b946184880bb0bb9150cbb56a0bdd34c25316e4bd0c6d\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=1e4fadea6f98d8fde14158e302e728e8ff9ef2b1dc8b4a52af1fcd70bf198877\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sentence-transformers sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
      "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.3.3\n"
     ]
    }
   ],
   "source": [
    "# install required libraries\n",
    "!pip3 install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wHrXaJsSLhrJ",
    "outputId": "0ac22b89-d3e7-435b-c562-32a1b0f4de91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/68/76c5d46cc6a48fddb759f585bc8728caa11bfc9b812ce6705fc5f99beab2/elasticsearch-7.11.0-py2.py3-none-any.whl (325kB)\n",
      "\r",
      "\u001b[K     |█                               | 10kB 22.0MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 20kB 14.6MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 30kB 12.9MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 40kB 12.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 51kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 61kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 71kB 8.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 81kB 9.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 92kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 102kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 112kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 122kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 133kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 143kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 153kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 163kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 174kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 184kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 194kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 204kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 215kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 225kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 235kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 245kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 256kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 266kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 276kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 286kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 296kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 307kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 317kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 327kB 7.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2020.12.5)\n",
      "Installing collected packages: elasticsearch\n",
      "Successfully installed elasticsearch-7.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nx6PkXGeh5s3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-v9U9E5h5gb",
    "outputId": "78a85659-81e3-408d-be0c-82b768b71f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMP1Wg7Bh5RT",
    "outputId": "a8827d11-55e5-478d-9caf-e609f49d06e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/BERT-FAQ\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/BERT-FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ESSxl0XiXAD",
    "outputId": "a5fb7a6f-2d11-4211-e0e8-a0e20bfe0bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t     metric.py\t  requirements.txt\n",
      "evaluation.py\t\t     notebook\t  reranker.py\n",
      "faq_bert_finetuning.py\t     output\t  searcher.py\n",
      "faq_bert.py\t\t     parser\t  shared\n",
      "hard_negatives_generator.py  __pycache__  training_data_generator.py\n",
      "indexer.py\t\t     README.md\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Fu6mIC_NKTRR"
   },
   "outputs": [],
   "source": [
    "# import required dependencies\n",
    "from evaluation import get_relevance_label_df\n",
    "from shared.utils import load_from_json\n",
    "from shared.utils import dump_to_json\n",
    "from shared.utils import make_dirs\n",
    "from reranker import ReRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_O3F8NYk19Go"
   },
   "outputs": [],
   "source": [
    "output_path=\"data/CovidFAQ/rank_results\"\n",
    "\n",
    "# load user_query ES results from json files\n",
    "es_output_path = output_path + \"/unsupervised\"\n",
    "es_query_by_question = load_from_json(es_output_path + '/es_query_by_question.json')\n",
    "es_query_by_answer = load_from_json(es_output_path + '/es_query_by_answer.json')\n",
    "es_query_by_question_answer = load_from_json(es_output_path + '/es_query_by_question_answer.json')\n",
    "es_query_by_question_answer_concat = load_from_json(es_output_path + '/es_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pyA4nPfi1885"
   },
   "outputs": [],
   "source": [
    "# load test_queries, relevance_label_df for ReRanker\n",
    "query_answer_pair_filepath = 'data/CovidFAQ/query_answer_pairs.json'\n",
    "relevance_label_df = get_relevance_label_df(query_answer_pair_filepath)\n",
    "test_queries = relevance_label_df[relevance_label_df['query_type'] == 'user_query'].question.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhodYHua180S",
    "outputId": "2e581ab8-5f93-4257-bd36-b6876e9662db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['What does Corona and Covid mean?',\n",
       "       'when will the social distancing end? and what is the economic consequent of the pandemic?',\n",
       "       'How do I go grocery shopping? ', 'what is covid 19',\n",
       "       \"What is COVID-19's definition?\", 'Should I stay home ?',\n",
       "       'Should I practice social distancing? ', 'How did it started',\n",
       "       'what are the 3 symptoms of covid-19', 'Should I wear a mask?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_queries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2S73_R42DCF",
    "outputId": "4c3bda86-209e-47ce-9c7f-70921cd70f16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of test queries\n",
    "len(test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-El9_2qsn20-"
   },
   "source": [
    "**#################### Triplet Loss ######################**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxcqS2Dj2liG"
   },
   "source": [
    "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__jcFHSRBZSY"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9ycYBipNnP9"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJMgG4aZKTN5",
    "outputId": "d07e2f63-0be3-4e42-e004-41a953ea4533"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 16:05:00 - Generating BERT top-k results ...\n",
      "2021-03-11 16:05:00 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:05:00 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:05:19 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [10:57<00:00,  1.64it/s]\n",
      "2021-03-11 16:16:17 - Re-ranking the top-k results ...\n",
      "2021-03-11 16:16:18 - Generating BERT top-k results ...\n",
      "2021-03-11 16:16:18 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:16:18 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:16:19 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [19:29<00:00,  1.08s/it]\n",
      "2021-03-11 16:35:50 - Re-ranking the top-k results ...\n",
      "2021-03-11 16:35:51 - Generating BERT top-k results ...\n",
      "2021-03-11 16:35:51 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:35:51 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:35:53 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:51<00:00,  1.16s/it]\n",
      "2021-03-11 16:56:45 - Re-ranking the top-k results ...\n",
      "2021-03-11 16:56:46 - Generating BERT top-k results ...\n",
      "2021-03-11 16:56:46 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:56:46 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_user_query_1.1\n",
      "2021-03-11 16:56:48 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [21:01<00:00,  1.17s/it]\n",
      "2021-03-11 17:17:51 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni5fBXXCM8oo"
   },
   "source": [
    "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YahPWqlrM4eU"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfz-PNgZM4FL"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90jQn9shzcsj",
    "outputId": "90b3ebc3-6588-41c6-8d5a-1c584f44120f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 17:22:28 - Generating BERT top-k results ...\n",
      "2021-03-11 17:22:28 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:22:28 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:22:45 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [11:03<00:00,  1.62it/s]\n",
      "2021-03-11 17:33:50 - Re-ranking the top-k results ...\n",
      "2021-03-11 17:33:51 - Generating BERT top-k results ...\n",
      "2021-03-11 17:33:51 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:33:51 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:33:52 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [19:43<00:00,  1.10s/it]\n",
      "2021-03-11 17:53:37 - Re-ranking the top-k results ...\n",
      "2021-03-11 17:53:39 - Generating BERT top-k results ...\n",
      "2021-03-11 17:53:39 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:53:39 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 17:53:40 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:46<00:00,  1.16s/it]\n",
      "2021-03-11 18:14:28 - Re-ranking the top-k results ...\n",
      "2021-03-11 18:14:29 - Generating BERT top-k results ...\n",
      "2021-03-11 18:14:29 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 18:14:29 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_user_query_1.1\n",
      "2021-03-11 18:14:30 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:40<00:00,  1.15s/it]\n",
      "2021-03-11 18:35:12 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0-VLGZ-Np04"
   },
   "source": [
    "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGUqO4kSNcGJ"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bkdb3DQON4A9"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9whF6pZTzfHK",
    "outputId": "bf22b5d8-0b41-421f-cd3d-feb86142f298"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 18:43:42 - Generating BERT top-k results ...\n",
      "2021-03-11 18:43:42 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 18:43:42 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 18:44:02 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [10:53<00:00,  1.65it/s]\n",
      "2021-03-11 18:54:56 - Re-ranking the top-k results ...\n",
      "2021-03-11 18:54:57 - Generating BERT top-k results ...\n",
      "2021-03-11 18:54:57 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 18:54:57 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 18:54:58 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [19:29<00:00,  1.08s/it]\n",
      "2021-03-11 19:14:29 - Re-ranking the top-k results ...\n",
      "2021-03-11 19:14:30 - Generating BERT top-k results ...\n",
      "2021-03-11 19:14:30 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 19:14:30 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 19:14:31 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:39<00:00,  1.15s/it]\n",
      "2021-03-11 19:35:13 - Re-ranking the top-k results ...\n",
      "2021-03-11 19:35:14 - Generating BERT top-k results ...\n",
      "2021-03-11 19:35:14 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 19:35:14 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_hard_faq_1.1\n",
      "2021-03-11 19:35:15 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:41<00:00,  1.15s/it]\n",
      "2021-03-11 19:55:59 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW6WhP1POh4R"
   },
   "source": [
    "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td1x8prBOXIo"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8ZPxcmWOny9"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWO9iOd4zjrX",
    "outputId": "c43ceec2-5548-40ad-dd7d-b028819404ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 19:56:01 - Generating BERT top-k results ...\n",
      "2021-03-11 19:56:01 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 19:56:01 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 19:56:18 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [10:47<00:00,  1.66it/s]\n",
      "2021-03-11 20:07:06 - Re-ranking the top-k results ...\n",
      "2021-03-11 20:07:07 - Generating BERT top-k results ...\n",
      "2021-03-11 20:07:07 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:07:07 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:07:09 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [19:23<00:00,  1.08s/it]\n",
      "2021-03-11 20:26:33 - Re-ranking the top-k results ...\n",
      "2021-03-11 20:26:34 - Generating BERT top-k results ...\n",
      "2021-03-11 20:26:34 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:26:34 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:26:35 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:34<00:00,  1.14s/it]\n",
      "2021-03-11 20:47:11 - Re-ranking the top-k results ...\n",
      "2021-03-11 20:47:12 - Generating BERT top-k results ...\n",
      "2021-03-11 20:47:12 - Load pretrained SentenceTransformer: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:47:12 - Load SentenceTransformer from folder: output/CovidFAQ/models/triplet_simple_faq_1.1\n",
      "2021-03-11 20:47:14 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [20:29<00:00,  1.14s/it]\n",
      "2021-03-11 21:07:44 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdMinNw0tEBa"
   },
   "source": [
    "**##################### Softmax Loss #####################**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQWBMnXNuN1r"
   },
   "source": [
    "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWbql3bypSdF"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXbORhXguIpu"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxveUtZbzlnb",
    "outputId": "dfd84281-6c71-46e6-b422-b3aa56503c79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 21:07:46 - Generating BERT top-k results ...\n",
      "2021-03-11 21:07:53 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [08:50<00:00,  2.03it/s]\n",
      "2021-03-11 21:16:44 - Re-ranking the top-k results ...\n",
      "2021-03-11 21:16:45 - Generating BERT top-k results ...\n",
      "2021-03-11 21:16:47 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [16:06<00:00,  1.12it/s]\n",
      "2021-03-11 21:32:55 - Re-ranking the top-k results ...\n",
      "2021-03-11 21:32:56 - Generating BERT top-k results ...\n",
      "2021-03-11 21:32:58 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [17:02<00:00,  1.05it/s]\n",
      "2021-03-11 21:50:02 - Re-ranking the top-k results ...\n",
      "2021-03-11 21:50:03 - Generating BERT top-k results ...\n",
      "2021-03-11 21:50:06 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [17:02<00:00,  1.05it/s]\n",
      "2021-03-11 22:07:09 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toLHtw4zugOk"
   },
   "source": [
    "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SBPKGt7ktRLQ"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8zMO_kPHtRBO"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vUWF6aUzmvS",
    "outputId": "2c576aa0-e482-480f-a98a-abe221817b62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-11 22:07:10 - Generating BERT top-k results ...\n",
      "2021-03-11 22:07:20 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [08:47<00:00,  2.04it/s]\n",
      "2021-03-11 22:16:08 - Re-ranking the top-k results ...\n",
      "2021-03-11 22:16:09 - Generating BERT top-k results ...\n",
      "2021-03-11 22:16:11 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [15:59<00:00,  1.12it/s]\n",
      "2021-03-11 22:32:12 - Re-ranking the top-k results ...\n",
      "2021-03-11 22:32:13 - Generating BERT top-k results ...\n",
      "2021-03-11 22:32:15 - Use pytorch device: cuda\n",
      " 35%|███▌      | 378/1078 [06:20<12:17,  1.05s/it]"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpyPOcybktpK",
    "outputId": "ff0911e7-2b60-491a-be6b-e0d9972e4ef0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 03:55:53 - Generating BERT top-k results ...\n",
      "2021-03-12 03:56:00 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:31<00:00,  2.39it/s]\n",
      "2021-03-12 04:03:33 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:03:34 - Generating BERT top-k results ...\n",
      "2021-03-12 04:03:36 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:28<00:00,  2.40it/s]\n",
      "2021-03-12 04:11:05 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNDZBk_GvM1z"
   },
   "source": [
    "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VmtGmXzrtQda"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pzg0l8rEtQZh"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Q_F0a8Qzon2",
    "outputId": "12b51f21-bb88-4084-9e38-4efb2ca60b6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 04:11:07 - Generating BERT top-k results ...\n",
      "2021-03-12 04:11:14 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [03:53<00:00,  4.61it/s]\n",
      "2021-03-12 04:15:08 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:15:09 - Generating BERT top-k results ...\n",
      "2021-03-12 04:15:11 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [06:58<00:00,  2.57it/s]\n",
      "2021-03-12 04:22:10 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:22:11 - Generating BERT top-k results ...\n",
      "2021-03-12 04:22:13 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:25<00:00,  2.42it/s]\n",
      "2021-03-12 04:29:40 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:29:41 - Generating BERT top-k results ...\n",
      "2021-03-12 04:29:42 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:25<00:00,  2.42it/s]\n",
      "2021-03-12 04:37:09 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2EgbhAkvgUc"
   },
   "source": [
    "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4tUfy5fOtP2M"
   },
   "outputs": [],
   "source": [
    "# define variables\n",
    "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
    "bert_model_path='output/CovidFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "x94VfKuitPva"
   },
   "outputs": [],
   "source": [
    "# create instance of ReRanker class\n",
    "r = ReRanker(\n",
    "    bert_model_path=bert_model_path, \n",
    "    test_queries=test_queries, relevance_label_df=relevance_label_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzcVcYUwzqLm",
    "outputId": "f445f886-d640-45b2-c011-ef8ad366972f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-12 04:37:10 - Generating BERT top-k results ...\n",
      "2021-03-12 04:37:16 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [03:56<00:00,  4.55it/s]\n",
      "2021-03-12 04:41:14 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:41:14 - Generating BERT top-k results ...\n",
      "2021-03-12 04:41:16 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:05<00:00,  2.53it/s]\n",
      "2021-03-12 04:48:23 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:48:24 - Generating BERT top-k results ...\n",
      "2021-03-12 04:48:26 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:35<00:00,  2.37it/s]\n",
      "2021-03-12 04:56:02 - Re-ranking the top-k results ...\n",
      "2021-03-12 04:56:03 - Generating BERT top-k results ...\n",
      "2021-03-12 04:56:05 - Use pytorch device: cuda\n",
      "100%|██████████| 1078/1078 [07:35<00:00,  2.37it/s]\n",
      "2021-03-12 05:03:42 - Re-ranking the top-k results ...\n"
     ]
    }
   ],
   "source": [
    "# generate directory structure\n",
    "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
    "make_dirs(reranked_output_path)\n",
    "\n",
    "# next, generate BERT, Re-ranked top-k results and dump to files\n",
    "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
    "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
    "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
    "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
    "\n",
    "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
    "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
    "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
    "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
    "\n",
    "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
    "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
    "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
    "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
    "\n",
    "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
    "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
    "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
    "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FWIvlvG7QFB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07.Generating_Reranked_Results.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
