{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "07.Generating_BERT_Prediction_Results.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIhLk6uIODF",
        "outputId": "0c669d5c-d109-4d7f-bc24-6112496d2f7a"
      },
      "source": [
        "# install required libraries\n",
        "!pip3 install sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/aa/f672ce489063c4ee7a566ebac1b723c53ac0cea19d9e36599cc241d8ed56/sentence-transformers-1.0.4.tar.gz (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.0MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.8.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 58.6MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 56.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-1.0.4-cp37-none-any.whl size=114307 sha256=2b6d6f69359ed177c65d8cda19278ca41181161d43d75f6c356fb1fcaca74dfb\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/ea/89/d0d2e013d951b6d23270aa9ca4018b82632ab7cd933c331316\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=cbdd411d21cd216fa14ad81da2c48662c41107b49ae0afe6fd054bfb1d611d5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.44 sentence-transformers-1.0.4 sentencepiece-0.1.95 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHrXaJsSLhrJ",
        "outputId": "d3158873-c776-4ce3-e91a-078543267e7e"
      },
      "source": [
        "!pip3 install elasticsearch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/93/461a042becf2a35a666fb7dbb2fa31f0f766dfd1b01e7d971f4ad51f0d69/elasticsearch-7.12.0-py2.py3-none-any.whl (334kB)\n",
            "\r\u001b[K     |█                               | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 14.2MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |████                            | 40kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 296kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 307kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 317kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 327kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 337kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2020.12.5)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6PkXGeh5s3"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-v9U9E5h5gb",
        "outputId": "d31aade5-26a6-488f-e90b-780bd06bbfe7"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMP1Wg7Bh5RT",
        "outputId": "7c96bab9-3fdd-40ec-ab61-f1061681a831"
      },
      "source": [
        "%cd /content/drive/MyDrive/BERT-FAQ"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BERT-FAQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ESSxl0XiXAD",
        "outputId": "fcaeb88d-ee7b-45ae-e5ae-b2b293415e2c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t     __init__.py  reranker.py\n",
            "evaluation.py\t\t     metric.py\t  searcher.py\n",
            "faq_bert_finetuning.py\t     notebook\t  shared\n",
            "faq_bert.py\t\t     output\t  training_data_generator.py\n",
            "faq_bert_ranker.py\t     parser\t  webserver.py\n",
            "hard_negatives_generator.py  __pycache__\n",
            "indexer.py\t\t     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6mIC_NKTRR"
      },
      "source": [
        "# import required dependencies\n",
        "from evaluation import get_relevance_label_df\n",
        "from shared.utils import load_from_json\n",
        "from shared.utils import dump_to_json\n",
        "from shared.utils import make_dirs\n",
        "from reranker import ReRanker"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O3F8NYk19Go"
      },
      "source": [
        "output_path=\"data/StackFAQ/rank_results\"\n",
        "\n",
        "# load user_query ES results from json files\n",
        "es_output_path = output_path + \"/unsupervised\"\n",
        "es_query_by_question = load_from_json(es_output_path + '/es_query_by_question.json')\n",
        "es_query_by_answer = load_from_json(es_output_path + '/es_query_by_answer.json')\n",
        "es_query_by_question_answer = load_from_json(es_output_path + '/es_query_by_question_answer.json')\n",
        "es_query_by_question_answer_concat = load_from_json(es_output_path + '/es_query_by_question_answer_concat.json')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA4nPfi1885"
      },
      "source": [
        "# load test_queries, relevance_label_df for ReRanker\n",
        "query_answer_pair_filepath = 'data/StackFAQ/query_answer_pairs.json'\n",
        "relevance_label_df = get_relevance_label_df(query_answer_pair_filepath)\n",
        "test_queries = relevance_label_df[relevance_label_df['query_type'] == 'user_query'].question.unique()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhodYHua180S",
        "outputId": "9b060124-489a-4678-9824-414264be791f"
      },
      "source": [
        "test_queries[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How to make font strikethrough on github.',\n",
              "       'Is it possible to get  strikethrough letter formatting on github markdown.',\n",
              "       'Making the text on github crossed out.',\n",
              "       'Introducing stikethrough formatting on markdown for github.',\n",
              "       'The <s> tag for font on github markdown doesnt work, is there an alternative?',\n",
              "       'Making the letters i write on github striked through.',\n",
              "       'Producing strikethrough text in github.',\n",
              "       'Does github support strikethrough letters?',\n",
              "       'How can I cross out my text on git hub?',\n",
              "       'I want to have strikethrough text on github, is this possible?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2S73_R42DCF",
        "outputId": "a74b35ed-61c7-45cb-ac1e-ab7ffb133e79"
      },
      "source": [
        "# total number of test queries\n",
        "len(test_queries)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDsNe63Nix7W"
      },
      "source": [
        "**1. Generating BERT prediction results from Answer (BERT-Q-a)\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvplanC2jY-y"
      },
      "source": [
        "# define rank_field parameter\n",
        "rank_field=\"BERT-Q-a\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcqS2Dj2liG"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jcFHSRBZSY"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ycYBipNnP9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJMgG4aZKTN5",
        "outputId": "672236ab-d1f7-4cad-a678-f5f985c87d43"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-05 07:33:27 - Generating BERT top-k results ...\n",
            "2021-04-05 07:33:27 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 07:33:27 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 07:33:46 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:18<00:00,  1.84s/it]\n",
            "2021-04-05 08:12:08 - Generating BERT top-k results ...\n",
            "2021-04-05 08:12:08 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 08:12:08 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 08:12:10 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [42:14<00:00,  2.03s/it]\n",
            "2021-04-05 08:54:28 - Generating BERT top-k results ...\n",
            "2021-04-05 08:54:28 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 08:54:28 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 08:54:30 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:36<00:00,  2.00s/it]\n",
            "2021-04-05 09:36:09 - Generating BERT top-k results ...\n",
            "2021-04-05 09:36:09 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 09:36:09 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-05 09:36:11 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [40:53<00:00,  1.96s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5fBXXCM8oo"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YahPWqlrM4eU"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfz-PNgZM4FL"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jQn9shzcsj",
        "outputId": "ef65e3e4-c997-4086-af23-a950d474d1bc"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 17:05:07 - Generating BERT top-k results ...\n",
            "2021-04-07 17:05:07 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 17:05:07 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 17:05:23 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:35<00:00,  1.85s/it]\n",
            "2021-04-07 17:44:01 - Generating BERT top-k results ...\n",
            "2021-04-07 17:44:01 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 17:44:01 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 17:44:03 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [42:48<00:00,  2.06s/it]\n",
            "2021-04-07 18:26:55 - Generating BERT top-k results ...\n",
            "2021-04-07 18:26:55 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 18:26:55 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 18:26:56 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:35<00:00,  2.00s/it]\n",
            "2021-04-07 19:08:35 - Generating BERT top-k results ...\n",
            "2021-04-07 19:08:36 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 19:08:36 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-07 19:08:37 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:00<00:00,  1.97s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-VLGZ-Np04"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGUqO4kSNcGJ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkdb3DQON4A9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9whF6pZTzfHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a185f892-1c9e-4130-d595-f7bfb9414ad9"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 19:49:42 - Generating BERT top-k results ...\n",
            "2021-04-07 19:49:42 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 19:49:42 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 19:49:54 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:48<00:00,  1.82s/it]\n",
            "2021-04-07 20:27:45 - Generating BERT top-k results ...\n",
            "2021-04-07 20:27:45 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 20:27:45 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 20:27:47 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [42:19<00:00,  2.03s/it]\n",
            "2021-04-07 21:10:09 - Generating BERT top-k results ...\n",
            "2021-04-07 21:10:09 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 21:10:09 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 21:10:11 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:09<00:00,  1.98s/it]\n",
            "2021-04-07 21:51:24 - Generating BERT top-k results ...\n",
            "2021-04-07 21:51:24 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 21:51:24 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-07 21:51:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [40:55<00:00,  1.97s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW6WhP1POh4R"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td1x8prBOXIo"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZPxcmWOny9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWO9iOd4zjrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0a49de-d152-4eab-95f7-987b8cd3fe58"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 22:32:26 - Generating BERT top-k results ...\n",
            "2021-04-07 22:32:26 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 22:32:26 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 22:32:35 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:07<00:00,  1.83s/it]\n",
            "2021-04-07 23:10:46 - Generating BERT top-k results ...\n",
            "2021-04-07 23:10:46 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 23:10:46 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 23:10:48 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [42:51<00:00,  2.06s/it]\n",
            "2021-04-07 23:53:43 - Generating BERT top-k results ...\n",
            "2021-04-07 23:53:43 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 23:53:43 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-07 23:53:45 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:42<00:00,  2.00s/it]\n",
            "2021-04-08 00:35:31 - Generating BERT top-k results ...\n",
            "2021-04-08 00:35:31 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 00:35:31 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 00:35:33 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:01<00:00,  1.97s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQWBMnXNuN1r"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWbql3bypSdF"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbORhXguIpu"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxveUtZbzlnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5969f4-fc38-446e-beb8-0bf353c3af66"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 01:16:38 - Generating BERT top-k results ...\n",
            "2021-04-08 01:16:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [33:11<00:00,  1.59s/it]\n",
            "2021-04-08 01:50:11 - Generating BERT top-k results ...\n",
            "2021-04-08 01:50:14 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:02<00:00,  1.88s/it]\n",
            "2021-04-08 02:29:19 - Generating BERT top-k results ...\n",
            "2021-04-08 02:29:22 - Use pytorch device: cuda\n",
            " 99%|█████████▉| 1242/1249 [37:16<00:12,  1.74s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La6gafqemRUN",
        "outputId": "af322731-fa39-462d-8231-ceeb04e311f0"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 08:32:18 - Generating BERT top-k results ...\n",
            "2021-04-08 08:32:31 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:11<00:00,  1.83s/it]\n",
            "2021-04-08 09:10:46 - Generating BERT top-k results ...\n",
            "2021-04-08 09:10:49 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [36:30<00:00,  1.75s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLHtw4zugOk"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPKGt7ktRLQ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMO_kPHtRBO"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vUWF6aUzmvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c69b866-8e26-4b8f-ee6f-40d4ea6e85d0"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 09:47:23 - Generating BERT top-k results ...\n",
            "2021-04-08 09:47:37 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [33:23<00:00,  1.60s/it]\n",
            "2021-04-08 10:21:03 - Generating BERT top-k results ...\n",
            "2021-04-08 10:21:06 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:02<00:00,  1.88s/it]\n",
            "2021-04-08 11:00:12 - Generating BERT top-k results ...\n",
            "2021-04-08 11:00:15 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:40<00:00,  1.81s/it]\n",
            "2021-04-08 11:37:58 - Generating BERT top-k results ...\n",
            "2021-04-08 11:38:01 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [36:13<00:00,  1.74s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDZBk_GvM1z"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtGmXzrtQda"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzg0l8rEtQZh"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q_F0a8Qzon2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d699c670-9d99-4eae-c677-8a0dd9cbc731"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 12:14:18 - Generating BERT top-k results ...\n",
            "2021-04-08 12:14:32 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [32:59<00:00,  1.58s/it]\n",
            "2021-04-08 12:47:34 - Generating BERT top-k results ...\n",
            "2021-04-08 12:47:37 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:58<00:00,  1.87s/it]\n",
            "2021-04-08 13:26:39 - Generating BERT top-k results ...\n",
            "2021-04-08 13:26:42 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:56<00:00,  1.82s/it]\n",
            "2021-04-08 14:04:41 - Generating BERT top-k results ...\n",
            "2021-04-08 14:04:44 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [36:00<00:00,  1.73s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2EgbhAkvgUc"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tUfy5fOtP2M"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x94VfKuitPva"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzcVcYUwzqLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4de7ff-7242-4c6c-cea8-42354842ff24"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 14:40:48 - Generating BERT top-k results ...\n",
            "2021-04-08 14:40:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [33:13<00:00,  1.60s/it]\n",
            "2021-04-08 15:14:13 - Generating BERT top-k results ...\n",
            "2021-04-08 15:14:16 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:18<00:00,  1.89s/it]\n",
            "2021-04-08 15:53:38 - Generating BERT top-k results ...\n",
            "2021-04-08 15:53:41 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:56<00:00,  1.82s/it]\n",
            "2021-04-08 16:31:41 - Generating BERT top-k results ...\n",
            "2021-04-08 16:31:43 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:14<00:00,  1.79s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRyZyUa9kTKP"
      },
      "source": [
        "**2. Generating BERT prediction results from Question (BERT-Q-q)\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYQ_Ixk4kZp6"
      },
      "source": [
        "# define rank_field parameter\n",
        "rank_field=\"BERT-Q-q\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZXbr22mlcPA"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkAAGDUrlWKr"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmZkX1mlWDG"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47GyLe1BlV7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb6a8da-9ea8-4e05-932c-7a275f19105e"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 17:09:03 - Generating BERT top-k results ...\n",
            "2021-04-08 17:09:03 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:09:04 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:09:17 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [23:00<00:00,  1.11s/it]\n",
            "2021-04-08 17:32:21 - Generating BERT top-k results ...\n",
            "2021-04-08 17:32:21 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:32:21 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:32:22 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [22:33<00:00,  1.08s/it]\n",
            "2021-04-08 17:55:00 - Generating BERT top-k results ...\n",
            "2021-04-08 17:55:00 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:55:00 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 17:55:02 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [22:28<00:00,  1.08s/it]\n",
            "2021-04-08 18:17:33 - Generating BERT top-k results ...\n",
            "2021-04-08 18:17:33 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 18:17:33 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 18:17:35 - Use pytorch device: cuda\n",
            " 75%|███████▍  | 933/1249 [16:39<05:42,  1.08s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFMLrXoV8XUY",
        "outputId": "186f4894-1ada-4dc3-9f70-d0943393f19f"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 19:25:06 - Generating BERT top-k results ...\n",
            "2021-04-08 19:25:06 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 19:25:06 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-04-08 19:25:17 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:27<00:00,  1.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5qc6jrl1DE"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW6EmCdAlVzK"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6poNdx0lVrh"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOJ8nTMslVkJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7df0e68-b84b-48df-cdbb-5efeb8c7fddd"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 19:39:47 - Generating BERT top-k results ...\n",
            "2021-04-08 19:39:47 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 19:39:47 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 19:39:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:12<00:00,  1.47it/s]\n",
            "2021-04-08 19:54:11 - Generating BERT top-k results ...\n",
            "2021-04-08 19:54:11 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 19:54:11 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 19:54:13 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:06<00:00,  1.47it/s]\n",
            "2021-04-08 20:08:22 - Generating BERT top-k results ...\n",
            "2021-04-08 20:08:22 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 20:08:22 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 20:08:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:23<00:00,  1.45it/s]\n",
            "2021-04-08 20:22:50 - Generating BERT top-k results ...\n",
            "2021-04-08 20:22:50 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 20:22:50 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-04-08 20:22:51 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:28<00:00,  1.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YycMuPkZoHSJ"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V5_byZblVT0"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leu15hKDlVMo"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDdzleOUlVFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31ba07a-9277-4cdb-8038-6356d71eccc7"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 20:37:22 - Generating BERT top-k results ...\n",
            "2021-04-08 20:37:22 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 20:37:22 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 20:37:33 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:04<00:00,  1.48it/s]\n",
            "2021-04-08 20:51:40 - Generating BERT top-k results ...\n",
            "2021-04-08 20:51:40 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 20:51:40 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 20:51:42 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:11<00:00,  1.47it/s]\n",
            "2021-04-08 21:05:56 - Generating BERT top-k results ...\n",
            "2021-04-08 21:05:56 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 21:05:56 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 21:05:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:07<00:00,  1.47it/s]\n",
            "2021-04-08 21:20:07 - Generating BERT top-k results ...\n",
            "2021-04-08 21:20:07 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 21:20:07 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-04-08 21:20:08 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:04<00:00,  1.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHFLDp3oLKm"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eEmYNyYlU5h"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZhB3zuSlUyb"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qee6WH2blUqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc43efd-d8ee-4125-ac73-2b0d565bec8b"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-08 21:34:16 - Generating BERT top-k results ...\n",
            "2021-04-08 21:34:16 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 21:34:16 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 21:34:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:03<00:00,  1.48it/s]\n",
            "2021-04-08 21:48:30 - Generating BERT top-k results ...\n",
            "2021-04-08 21:48:30 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 21:48:30 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 21:48:32 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:07<00:00,  1.47it/s]\n",
            "2021-04-08 22:02:42 - Generating BERT top-k results ...\n",
            "2021-04-08 22:02:42 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 22:02:42 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 22:02:43 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [14:08<00:00,  1.47it/s]\n",
            "2021-04-08 22:16:55 - Generating BERT top-k results ...\n",
            "2021-04-08 22:16:55 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 22:16:55 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-08 22:16:56 - Use pytorch device: cuda\n",
            " 82%|████████▏ | 1023/1249 [11:35<02:32,  1.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIi9fOJy6xkr",
        "outputId": "e0f165e8-dfc0-4326-a97e-5eb05f7dc4b1"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 04:37:02 - Generating BERT top-k results ...\n",
            "2021-04-09 04:37:02 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-09 04:37:02 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-04-09 04:37:11 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [13:27<00:00,  1.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqE2Blb3oPw1"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8noZJecmltk"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_iwsKK6mljZ"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkfY7SAAmlZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64ba4572-ddd3-4d92-849c-23bf729f6501"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 04:50:41 - Generating BERT top-k results ...\n",
            "2021-04-09 04:50:53 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:27<00:00,  1.67it/s]\n",
            "2021-04-09 05:03:23 - Generating BERT top-k results ...\n",
            "2021-04-09 05:03:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:32<00:00,  1.66it/s]\n",
            "2021-04-09 05:16:00 - Generating BERT top-k results ...\n",
            "2021-04-09 05:16:02 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:32<00:00,  1.66it/s]\n",
            "2021-04-09 05:28:37 - Generating BERT top-k results ...\n",
            "2021-04-09 05:28:39 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:34<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lO2b2wxoUWS"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lctMrtS0mlHO"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NvD-Sgmk9l"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sIIkgKhmk4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246ebd87-5784-47c2-90ac-6c96c8190664"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 05:41:16 - Generating BERT top-k results ...\n",
            "2021-04-09 05:41:30 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:32<00:00,  1.66it/s]\n",
            "2021-04-09 05:54:05 - Generating BERT top-k results ...\n",
            "2021-04-09 05:54:07 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:33<00:00,  1.66it/s]\n",
            "2021-04-09 06:06:43 - Generating BERT top-k results ...\n",
            "2021-04-09 06:06:45 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:36<00:00,  1.65it/s]\n",
            "2021-04-09 06:19:24 - Generating BERT top-k results ...\n",
            "2021-04-09 06:19:26 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:41<00:00,  1.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcXgJnWboXMy"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU_9X36LnNNi"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdUQo5RznNCE"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjDLglyJnM28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf3791b-2dbe-477c-b35d-740aacf26c1a"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 06:32:10 - Generating BERT top-k results ...\n",
            "2021-04-09 06:32:22 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:39<00:00,  1.64it/s]\n",
            "2021-04-09 06:45:04 - Generating BERT top-k results ...\n",
            "2021-04-09 06:45:06 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:38<00:00,  1.65it/s]\n",
            "2021-04-09 06:57:47 - Generating BERT top-k results ...\n",
            "2021-04-09 06:57:49 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:38<00:00,  1.65it/s]\n",
            "2021-04-09 07:10:31 - Generating BERT top-k results ...\n",
            "2021-04-09 07:10:33 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:38<00:00,  1.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZubZiiwqobdT"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEoVIgvQnMf-"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaVyBLM9nMUn"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydEelLV-nMIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8ab3a6-e442-46f1-bd01-2323736f6a9d"
      },
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 07:23:15 - Generating BERT top-k results ...\n",
            "2021-04-09 07:23:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:35<00:00,  1.65it/s]\n",
            "2021-04-09 07:36:02 - Generating BERT top-k results ...\n",
            "2021-04-09 07:36:04 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:41<00:00,  1.64it/s]\n",
            "2021-04-09 07:48:48 - Generating BERT top-k results ...\n",
            "2021-04-09 07:48:50 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:43<00:00,  1.64it/s]\n",
            "2021-04-09 08:01:37 - Generating BERT top-k results ...\n",
            "2021-04-09 08:01:39 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [12:41<00:00,  1.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbmSw6KqVuEH"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}