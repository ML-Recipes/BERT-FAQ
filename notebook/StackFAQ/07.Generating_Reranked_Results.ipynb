{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "07_Generating_Reranked_Results_StackFAQ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIhLk6uIODF",
        "outputId": "192fde61-fe57-4274-d17e-503bfec3733c"
      },
      "source": [
        "# install required libraries\n",
        "!pip3 install sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/e2/84d6acfcee2d83164149778a33b6bdd1a74e1bcb59b2b2cd1b861359b339/sentence-transformers-0.4.1.2.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.4MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 41.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.4.1.2-cp37-none-any.whl size=103068 sha256=9a5cc4560970cd4fb87611c2f1964525ce0339c5ddf022e42bb4afc1d18473cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/33/d1/5703dd56199c09d4a1b41e0c07fb4e7765a84d787cbdc48ac3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=32b83891a5f47a9ee23f1ce8391b5c0985c3e0972516b1d37f0348a6a40eaef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers, sentencepiece, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.4.1.2 sentencepiece-0.1.95 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHrXaJsSLhrJ",
        "outputId": "599f5078-de48-4793-c438-0a0b650afff1"
      },
      "source": [
        "!pip3 install elasticsearch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/68/76c5d46cc6a48fddb759f585bc8728caa11bfc9b812ce6705fc5f99beab2/elasticsearch-7.11.0-py2.py3-none-any.whl (325kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch) (1.24.3)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6PkXGeh5s3"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-v9U9E5h5gb",
        "outputId": "c1501181-b637-40a7-a358-75806b358ed3"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMP1Wg7Bh5RT",
        "outputId": "e7cb6590-e18d-490a-ab99-8d1c07820224"
      },
      "source": [
        "%cd /content/drive/MyDrive/BERT-FAQ"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/BERT-FAQ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ESSxl0XiXAD",
        "outputId": "286f56bf-28bf-4e34-83a7-d2558bc05893"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t\t\t     metric.py\t  requirements.txt\n",
            "evaluation.py\t\t     notebook\t  reranker.py\n",
            "faq_bert_finetuning.py\t     output\t  searcher.py\n",
            "faq_bert.py\t\t     parser\t  shared\n",
            "hard_negatives_generator.py  __pycache__  training_data_generator.py\n",
            "indexer.py\t\t     README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6mIC_NKTRR"
      },
      "source": [
        "# import required dependencies\n",
        "from evaluation import get_relevance_label_df\n",
        "from shared.utils import load_from_json\n",
        "from shared.utils import dump_to_json\n",
        "from shared.utils import make_dirs\n",
        "from reranker import ReRanker"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O3F8NYk19Go"
      },
      "source": [
        "output_path=\"data/StackFAQ/rank_results\"\n",
        "\n",
        "# load user_query ES results from json files\n",
        "es_output_path = output_path + \"/unsupervised\"\n",
        "es_query_by_question = load_from_json(es_output_path + '/es_query_by_question.json')\n",
        "es_query_by_answer = load_from_json(es_output_path + '/es_query_by_answer.json')\n",
        "es_query_by_question_answer = load_from_json(es_output_path + '/es_query_by_question_answer.json')\n",
        "es_query_by_question_answer_concat = load_from_json(es_output_path + '/es_query_by_question_answer_concat.json')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyA4nPfi1885"
      },
      "source": [
        "# load test_queries, relevance_label_df for ReRanker\n",
        "query_answer_pair_filepath = 'data/StackFAQ/query_answer_pairs.json'\n",
        "relevance_label_df = get_relevance_label_df(query_answer_pair_filepath)\n",
        "test_queries = relevance_label_df[relevance_label_df['query_type'] == 'user_query'].question.unique()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhodYHua180S",
        "outputId": "27048f1a-0322-44b7-e75e-231b08ab1a51"
      },
      "source": [
        "test_queries[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['How to make font strikethrough on github.',\n",
              "       'Is it possible to get  strikethrough letter formatting on github markdown.',\n",
              "       'Making the text on github crossed out.',\n",
              "       'Introducing stikethrough formatting on markdown for github.',\n",
              "       'The <s> tag for font on github markdown doesnt work, is there an alternative?',\n",
              "       'Making the letters i write on github striked through.',\n",
              "       'Producing strikethrough text in github.',\n",
              "       'Does github support strikethrough letters?',\n",
              "       'How can I cross out my text on git hub?',\n",
              "       'I want to have strikethrough text on github, is this possible?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2S73_R42DCF",
        "outputId": "aab5b70f-4624-45a3-bef0-869bec5bf4a3"
      },
      "source": [
        "# total number of test queries\n",
        "len(test_queries)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-El9_2qsn20-"
      },
      "source": [
        "**#################### Triplet Loss ######################**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcqS2Dj2liG"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__jcFHSRBZSY"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ycYBipNnP9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJMgG4aZKTN5",
        "outputId": "d48eb024-e616-4324-fd72-8a5487b947bc"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 08:31:31 - Generating BERT top-k results ...\n",
            "2021-03-07 08:31:31 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 08:31:31 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 08:31:38 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:33<00:00,  1.12it/s]\n",
            "2021-03-07 08:50:13 - Re-ranking the top-k results ...\n",
            "2021-03-07 08:50:15 - Generating BERT top-k results ...\n",
            "2021-03-07 08:50:15 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 08:50:15 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 08:50:17 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:32<00:00,  1.07it/s]\n",
            "2021-03-07 09:09:52 - Re-ranking the top-k results ...\n",
            "2021-03-07 09:09:54 - Generating BERT top-k results ...\n",
            "2021-03-07 09:09:54 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 09:09:54 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 09:09:55 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:10<00:00,  1.09it/s]\n",
            "2021-03-07 09:29:09 - Re-ranking the top-k results ...\n",
            "2021-03-07 09:29:11 - Generating BERT top-k results ...\n",
            "2021-03-07 09:29:11 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 09:29:11 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_user_query_1.1\n",
            "2021-03-07 09:29:12 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:57<00:00,  1.10it/s]\n",
            "2021-03-07 09:48:12 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5fBXXCM8oo"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YahPWqlrM4eU"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfz-PNgZM4FL"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jQn9shzcsj",
        "outputId": "d712ecc6-06c9-4aed-9e83-dee21787bebe"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 09:48:14 - Generating BERT top-k results ...\n",
            "2021-03-07 09:48:14 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 09:48:14 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 09:48:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:04<00:00,  1.15it/s]\n",
            "2021-03-07 10:06:31 - Re-ranking the top-k results ...\n",
            "2021-03-07 10:06:33 - Generating BERT top-k results ...\n",
            "2021-03-07 10:06:33 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:06:33 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:06:34 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:16<00:00,  1.08it/s]\n",
            "2021-03-07 10:25:54 - Re-ranking the top-k results ...\n",
            "2021-03-07 10:25:56 - Generating BERT top-k results ...\n",
            "2021-03-07 10:25:56 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:25:56 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:25:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:57<00:00,  1.10it/s]\n",
            "2021-03-07 10:44:57 - Re-ranking the top-k results ...\n",
            "2021-03-07 10:44:59 - Generating BERT top-k results ...\n",
            "2021-03-07 10:44:59 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:44:59 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_user_query_1.1\n",
            "2021-03-07 10:45:01 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:48<00:00,  1.11it/s]\n",
            "2021-03-07 11:03:52 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-VLGZ-Np04"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGUqO4kSNcGJ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkdb3DQON4A9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9whF6pZTzfHK",
        "outputId": "5ff134a4-55c5-413f-cfe6-5d771d63a424"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 11:03:54 - Generating BERT top-k results ...\n",
            "2021-03-07 11:03:54 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:03:54 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:04:06 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:06<00:00,  1.15it/s]\n",
            "2021-03-07 11:22:14 - Re-ranking the top-k results ...\n",
            "2021-03-07 11:22:17 - Generating BERT top-k results ...\n",
            "2021-03-07 11:22:17 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:22:17 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:22:18 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:09<00:00,  1.09it/s]\n",
            "2021-03-07 11:41:30 - Re-ranking the top-k results ...\n",
            "2021-03-07 11:41:32 - Generating BERT top-k results ...\n",
            "2021-03-07 11:41:32 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:41:32 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 11:41:34 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:56<00:00,  1.10it/s]\n",
            "2021-03-07 12:00:33 - Re-ranking the top-k results ...\n",
            "2021-03-07 12:00:35 - Generating BERT top-k results ...\n",
            "2021-03-07 12:00:35 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 12:00:35 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_hard_faq_1.1\n",
            "2021-03-07 12:00:36 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:44<00:00,  1.11it/s]\n",
            "2021-03-07 12:19:23 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW6WhP1POh4R"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td1x8prBOXIo"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZPxcmWOny9"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWO9iOd4zjrX",
        "outputId": "d6f0b5ba-8ff2-40d2-d97c-db972d5a972a"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-07 12:19:26 - Generating BERT top-k results ...\n",
            "2021-03-07 12:19:26 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:19:26 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:19:35 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:02<00:00,  1.15it/s]\n",
            "2021-03-07 12:37:40 - Re-ranking the top-k results ...\n",
            "2021-03-07 12:37:42 - Generating BERT top-k results ...\n",
            "2021-03-07 12:37:42 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:37:42 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:37:43 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:17<00:00,  1.08it/s]\n",
            "2021-03-07 12:57:03 - Re-ranking the top-k results ...\n",
            "2021-03-07 12:57:06 - Generating BERT top-k results ...\n",
            "2021-03-07 12:57:06 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:57:06 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 12:57:07 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [19:03<00:00,  1.09it/s]\n",
            "2021-03-07 13:16:14 - Re-ranking the top-k results ...\n",
            "2021-03-07 13:16:16 - Generating BERT top-k results ...\n",
            "2021-03-07 13:16:16 - Load pretrained SentenceTransformer: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 13:16:16 - Load SentenceTransformer from folder: output/StackFAQ/models/triplet_simple_faq_1.1\n",
            "2021-03-07 13:16:17 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [18:48<00:00,  1.11it/s]\n",
            "2021-03-07 13:35:08 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdMinNw0tEBa"
      },
      "source": [
        "**##################### Softmax Loss #####################**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQWBMnXNuN1r"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWbql3bypSdF"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbORhXguIpu"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxveUtZbzlnb",
        "outputId": "e9336f11-4781-4808-c0af-365157cf3dc0"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-08 17:39:14 - Generating BERT top-k results ...\n",
            "2021-03-08 17:39:28 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [34:48<00:00,  1.67s/it]\n",
            "2021-03-08 18:14:19 - Re-ranking the top-k results ...\n",
            "2021-03-08 18:14:21 - Generating BERT top-k results ...\n",
            "2021-03-08 18:14:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:40<00:00,  1.91s/it]\n",
            "2021-03-08 18:54:07 - Re-ranking the top-k results ...\n",
            "2021-03-08 18:54:09 - Generating BERT top-k results ...\n",
            "2021-03-08 18:54:12 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:44<00:00,  1.86s/it]\n",
            "2021-03-08 19:32:59 - Re-ranking the top-k results ...\n",
            "2021-03-08 19:33:02 - Generating BERT top-k results ...\n",
            "2021-03-08 19:33:05 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:02<00:00,  1.83s/it]\n",
            "2021-03-08 20:11:10 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLHtw4zugOk"
      },
      "source": [
        "**Re-ranking results using query_type=\"user_query\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPKGt7ktRLQ"
      },
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMO_kPHtRBO"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vUWF6aUzmvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d1306b-b019-4824-e8e7-cddc8b79f747"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-08 20:11:14 - Generating BERT top-k results ...\n",
            "2021-03-08 20:11:25 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [34:31<00:00,  1.66s/it]\n",
            "2021-03-08 20:46:00 - Re-ranking the top-k results ...\n",
            "2021-03-08 20:46:02 - Generating BERT top-k results ...\n",
            "2021-03-08 20:46:05 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:57<00:00,  1.92s/it]\n",
            "2021-03-08 21:26:05 - Re-ranking the top-k results ...\n",
            "2021-03-08 21:26:08 - Generating BERT top-k results ...\n",
            "2021-03-08 21:26:11 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:37<00:00,  1.86s/it]\n",
            "2021-03-08 22:04:51 - Re-ranking the top-k results ...\n",
            "2021-03-08 22:04:54 - Generating BERT top-k results ...\n",
            "2021-03-08 22:04:57 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [37:41<00:00,  1.81s/it]\n",
            "2021-03-08 22:42:42 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDZBk_GvM1z"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"hard\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmtGmXzrtQda"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzg0l8rEtQZh"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q_F0a8Qzon2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3430f81f-b1e9-421b-f217-f7a10acabaa2"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-09 04:08:06 - Generating BERT top-k results ...\n",
            "2021-03-09 04:08:21 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:09<00:00,  1.98s/it]\n",
            "2021-03-09 04:49:34 - Re-ranking the top-k results ...\n",
            "2021-03-09 04:49:36 - Generating BERT top-k results ...\n",
            "2021-03-09 04:49:39 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:37<00:00,  1.90s/it]\n",
            "2021-03-09 05:29:19 - Re-ranking the top-k results ...\n",
            "2021-03-09 05:29:22 - Generating BERT top-k results ...\n",
            "2021-03-09 05:29:24 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:35<00:00,  1.85s/it]\n",
            "2021-03-09 06:08:03 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2EgbhAkvgUc"
      },
      "source": [
        "**Re-ranking results using query_type=\"faq\"; neg_type=\"simple\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tUfy5fOtP2M"
      },
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='output/StackFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x94VfKuitPva"
      },
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df, loss_type=loss_type\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzcVcYUwzqLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b878608a-b6c8-41fb-f559-039c18707e37"
      },
      "source": [
        "# generate directory structure\n",
        "reranked_output_path = output_path + \"/supervised/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(reranked_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, reranked_output_path + '/bert_query_by_question.json')\n",
        "reranked_query_by_question = r.get_reranked_results(bert_query_by_question)\n",
        "dump_to_json(reranked_query_by_question, reranked_output_path + '/reranked_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, reranked_output_path + '/bert_query_by_answer.json')\n",
        "reranked_query_by_answer = r.get_reranked_results(bert_query_by_answer)\n",
        "dump_to_json(reranked_query_by_answer, reranked_output_path + '/reranked_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, reranked_output_path + '/bert_query_by_question_answer.json')\n",
        "reranked_query_by_question_answer = r.get_reranked_results(bert_query_by_question_answer)\n",
        "dump_to_json(reranked_query_by_question_answer, reranked_output_path + '/reranked_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, reranked_output_path + '/bert_query_by_question_answer_concat.json')\n",
        "reranked_query_by_question_answer_concat = r.get_reranked_results(bert_query_by_question_answer_concat)\n",
        "dump_to_json(reranked_query_by_question_answer_concat, reranked_output_path + '/reranked_query_by_question_answer_concat.json')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-09 06:08:07 - Generating BERT top-k results ...\n",
            "2021-03-09 06:08:18 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [34:30<00:00,  1.66s/it]\n",
            "2021-03-09 06:42:51 - Re-ranking the top-k results ...\n",
            "2021-03-09 06:42:54 - Generating BERT top-k results ...\n",
            "2021-03-09 06:42:56 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [41:09<00:00,  1.98s/it]\n",
            "2021-03-09 07:24:09 - Re-ranking the top-k results ...\n",
            "2021-03-09 07:24:12 - Generating BERT top-k results ...\n",
            "2021-03-09 07:24:14 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [39:30<00:00,  1.90s/it]\n",
            "2021-03-09 08:03:48 - Re-ranking the top-k results ...\n",
            "2021-03-09 08:03:51 - Generating BERT top-k results ...\n",
            "2021-03-09 08:03:54 - Use pytorch device: cuda\n",
            "100%|██████████| 1249/1249 [38:24<00:00,  1.84s/it]\n",
            "2021-03-09 08:42:21 - Re-ranking the top-k results ...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FWIvlvG7QFB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}